---
---

# Visual Perception, Emotion & Cognition Laboratory

Our primary goal is to understand how basic neural and cognitive mechanisms shape what people see and hear. We employ psychophysics and modeling to understand how basic visual processes allow people to see and understand both simple and complex patterns like shapes, facial expressions and gaze. Our goal is to use vision science to answer core questions about the human mind and the nature of visual awareness while making an impact on multiple disciplines within psychology. We also collaborate to examine the role of perceptual processes in clinical, affective and social outcomes.

{%
  include button.html
  link="research"
  text="See our publications"
  icon="fa-solid fa-arrow-right"
  flip=true
%}

## Areas of Research

{% capture text %}
Billions of bits of information arrive at the retina every moment, but only a fraction of this information reaches awareness. Which visual processes require awareness and which do not? How do different types of visual masking work, and what do their similarities and differences tell us about general mechanisms of visual awareness, if there are any? Determining the perceptual processes that do and do not require awareness may reveal the purpose of conscious vision.
{% endcapture%}
{% include feature.html image="images/icon.png" title="Awareness/Consciousness" text=text%}

{% capture text %}
Recent work suggests that, compared to unaffected controls, anxious adults and children are more likely to appraise ambiguous information as threatening, although in children this work is limited to interpretations of linguistic information. Our own work in the VPEC Lab illustrates that a similar negative bias occurs when non-anxious adults interpret visual information, like facial expressions. Yet visual bias among anxious adults and children and the link between visual and linguistic cognitive processes across development remain uncharted territory.
{% endcapture%}
{% include feature.html image="images/icon.png" title="Perception Bias and Anxiety" text=text% flip=true}

{% capture text %}
But there is a paradox about this kind of perception. Attention and memory have limited capacity, only allowing people to see and remember information about a few things at a time. How does the visual system overcome these bottlenecks to see the gist of a scene? What mechanisms integrate and summarize lots of visual information, all at once, allowing people to appreciate groups of things as collective entities?
{% endcapture%}
{% include feature.html image="images/icon.png" title="Perceptual Integration/Ensemble Perception" text=text%}

{% capture text %}
Autism spectrum disorder (ASD) is increasingly prevalent, affecting 1 in every 68 children in the United States. In addition to presenting children with pervasive social and behavioral challenges, ASD is also associated with changes in visual perception. Do children with ASD actually see their worlds differently than other children? How do children with ASD perceive complex social cues, like a person's gaze direction, and how might visual perception influence the way kids with ASD understand another person's mental state or engage in social interactions? How do people with ASD perceive gaze on a robot's face?
{% endcapture%}
{% include feature.html image="images/icon.png" title="Autism Spectrum Disorder and Visual Perception" text=text flip=true%}

{% capture text %}
Faces are fascinating. They're visually complex, they're dynamic and they're just about everywhere. People contort their faces to express their emotions and direct their attention. Faces also provide a means to understand what other people are thinking, feeling and seeing.
While most people have no trouble discriminating extreme facial displays, like seething rage or direct gaze, the facial cues people typically encounter are more subtle and visible for only an instant. How much about a person's internal state can we actually access in an instant? How does the visual system determine where a person is looking? Does hearing emotional sounds change the way people see emotion?
{% endcapture%}
{% include feature.html image="images/icon.png" title="Face/Emotion Perception" text=text%}

{% capture text %}
The world is full of redundancy. Many objects and people appear strikingly similar. Yet somehow people understand our world in terms of distinct categories: tall or flat, happy or neutral, walking toward me or to the side, familiar or unfamiliar.
This segmentation is really important when viewing many things at once, allowing people find the odd-ball, or the object of a search. What visual mechanisms allow people to parse lots of similar information at once, segmenting the world into distinct categories and directing attention toward the qualities that make each object or person unique?
{% endcapture%}
{% include feature.html image="images/icon.png" title="Perceptual Segmentation" text=text flip=true%}

{% capture text %}
What is visual experience like in childhood? Many perceptual abilities take years to develop, including distinguishing objects in time and space, filtering out distracting visual information and even remembering what has been seen. Yet, just like adults, children must navigate crowded and cluttered environments. Is the developing visual system equipped with any mechanisms for seeing many things at once? How does the ability to see the gist develop from pre-school age to adulthood? How do children perceive complex social cues like gaze and facial expression?
{% endcapture%}
{% include feature.html image="images/icon.png" title="Perceptual Development" text=text%}
