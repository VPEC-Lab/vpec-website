<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>VPEC Lab</title>

<link rel="icon" href="/vpec-lab.github.io/images/icon.png">

<meta name="title" content="">
<meta name="description" content="In the Visual Perception, Emotion &amp; Cognition (VPEC) Laboratory, we study visual perception. Our primary goal is to understand how basic neural and cognitive mechanisms shape what people see and hear. We also collaborate to examine the role of perceptual processes in clinical, affective and social outcomes.">

<meta property="og:title" content="">
<meta property="og:site_title" content="VPEC Lab">
<meta property="og:description" content="In the Visual Perception, Emotion &amp; Cognition (VPEC) Laboratory, we study visual perception. Our primary goal is to understand how basic neural and cognitive mechanisms shape what people see and hear. We also collaborate to examine the role of perceptual processes in clinical, affective and social outcomes.">
<meta property="og:url" content="">
<meta property="og:image" content="/vpec-lab.github.io/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="">
<meta property="twitter:description" content="In the Visual Perception, Emotion &amp; Cognition (VPEC) Laboratory, we study visual perception. Our primary goal is to understand how basic neural and cognitive mechanisms shape what people see and hear. We also collaborate to examine the role of perceptual processes in clinical, affective and social outcomes.">
<meta property="twitter:url" content="">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/vpec-lab.github.io/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "",
    "description": "In the Visual Perception, Emotion & Cognition (VPEC) Laboratory, we study visual perception. Our primary goal is to understand how basic neural and cognitive mechanisms shape what people see and hear. We also collaborate to examine the role of perceptual processes in clinical, affective and social outcomes.",
    "headline": "",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/vpec-lab.github.io/images/icon.png" }
    },
    "url": ""
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/vpec-lab.github.io/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="preload" as="style" onload="this.onload = null; this.rel = 'stylesheet';">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/vpec-lab.github.io/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/all.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/background.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/body.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/button.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/card.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/code.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/float.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/font.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/form.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/header.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/image.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/link.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/list.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/main.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/section.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/table.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/vpec-lab.github.io/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/vpec-lab.github.io/_scripts/anchors.js"></script>

  <script src="/vpec-lab.github.io/_scripts/dark-mode.js"></script>

  <script src="/vpec-lab.github.io/_scripts/fetch-tags.js"></script>

  <script src="/vpec-lab.github.io/_scripts/search.js"></script>

  <script src="/vpec-lab.github.io/_scripts/site-search.js"></script>

  <script src="/vpec-lab.github.io/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/vpec-lab.github.io/images/background.jpg')" data-dark="true" data-big>
  <a href="/vpec-lab.github.io/" class="home">
    
      <span class="logo">
        
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-40 -60 80 100">
  <style>
    .bubble {
      animation: float 2s ease-out both infinite var(--delay);
    }
    @keyframes float {
      0% {
        opacity: 0;
      }
      50% {
        transform: translateY(0);
        opacity: 0;
      }
      75% {
        opacity: 1;
      }
      100% {
        opacity: 0;
        transform: translateY(-40px);
      }
    }
  </style>
  <g fill="currentColor" opacity="0.5">
    <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.1s"></circle>
    <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.4s"></circle>
    <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 1.1s"></circle>
  </g>
  <path fill="#38bdf8" d="
      M 0 -22.5
      L -19.5 -11.25
      L -19.5 11.25
      L 0 22.5
      L 19.5 11.25
      L 19.5 -11.25
      z
    "></path>
  <path fill="#bae6fd" d="
      M 0 -22.5
      L -19.5 -11.25
      L 0 0
      L 19.5 -11.25
      z
    "></path>
  <path fill="none" stroke="currentColor" stroke-width="5" d="
      M -18 -53
      L -10 -53
      L -10 -29.2
      L -30.3 -17.5
      L -30.3 17.5
      L 0 35
      L 30.3 17.5
      L 30.3 -17.5
      L 10 -29.2
      L 10 -53
      L 18 -53
    "></path>
</svg>

        
      </span>
    
    
      <span class="title" data-tooltip="Home">
        
          <span>VPEC Lab</span>
        
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/vpec-lab.github.io/publications/" data-tooltip="Published works">
          Publications
        </a>
      
    
      
        <a href="/vpec-lab.github.io/projects/" data-tooltip="Software, datasets, and more">
          Projects
        </a>
      
    
      
        <a href="/vpec-lab.github.io/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/vpec-lab.github.io/media/" data-tooltip="Lab pictures and events">
          Media
        </a>
      
    
      
        <a href="/vpec-lab.github.io/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - wrap each table in div to allow for scrolling
  - filter out blank sections
-->








  
  
  

  <section class="background" data-size="page">
    <h1 id="visual-perception-emotion--cognition-laboratory">Visual Perception, Emotion &amp; Cognition Laboratory</h1>

<p>Our primary goal is to understand how basic neural and cognitive mechanisms shape what people see and hear. We employ psychophysics and modeling to understand how basic visual processes allow people to see and understand both simple and complex patterns like shapes, facial expressions and gaze. Our goal is to use vision science to answer core questions about the human mind and the nature of visual awareness while making an impact on multiple disciplines within psychology. We also collaborate to examine the role of perceptual processes in clinical, affective and social outcomes.</p>

<div class="button-wrapper">
    <a class="button" href="/vpec-lab.github.io/research" data-style="" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>See our publications</span>
      
    </a>
  </div>

<h2 id="areas-of-research">Areas of Research</h2>

<div class="feature">
  <a class="feature-image" aria-label="Awareness/Consciousness">
    <img src="https://images.theconversation.com/files/411896/original/file-20210719-25-191cj1c.jpeg?ixlib=rb-1.1.0&rect=197%2C188%2C5604%2C3799&q=45&auto=format&w=926&fit=clip" loading="lazy" alt="Awareness/Consciousness" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Awareness/Consciousness</p>
    
    
<p>Billions of bits of information arrive at the retina every moment, but only a fraction of this information reaches awareness. Which visual processes require awareness and which do not? How do different types of visual masking work, and what do their similarities and differences tell us about general mechanisms of visual awareness, if there are any? Determining the perceptual processes that do and do not require awareness may reveal the purpose of conscious vision.</p>

  </div>
</div>

<div class="feature" data-flip="">
  <a class="feature-image" aria-label="Perception Bias and Anxiety">
    <img src="https://images.unsplash.com/photo-1633104326066-504911cc1347?q=80&w=1470&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" loading="lazy" alt="Perception Bias and Anxiety" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Perception Bias and Anxiety</p>
    
    
<p>Recent work suggests that, compared to unaffected controls, anxious adults and children are more likely to appraise ambiguous information as threatening, although in children this work is limited to interpretations of linguistic information. Our own work in the VPEC Lab illustrates that a similar negative bias occurs when non-anxious adults interpret visual information, like facial expressions. Yet visual bias among anxious adults and children and the link between visual and linguistic cognitive processes across development remain uncharted territory.</p>

  </div>
</div>

<div class="feature">
  <a class="feature-image" aria-label="Perceptual Integration/Ensemble Perception">
    <img src="https://images.unsplash.com/photo-1573358695783-005699a7fc94?q=80&w=1471&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" loading="lazy" alt="Perceptual Integration/Ensemble Perception" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Perceptual Integration/Ensemble Perception</p>
    
    
<p>But there is a paradox about this kind of perception. Attention and memory have limited capacity, only allowing people to see and remember information about a few things at a time. How does the visual system overcome these bottlenecks to see the gist of a scene? What mechanisms integrate and summarize lots of visual information, all at once, allowing people to appreciate groups of things as collective entities?</p>

  </div>
</div>

<div class="feature" data-flip="">
  <a class="feature-image" aria-label="Autism Spectrum Disorder and Visual Perception">
    <img src="https://images.unsplash.com/photo-1495900593237-22dc861b231d?q=80&w=1470&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" loading="lazy" alt="Autism Spectrum Disorder and Visual Perception" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Autism Spectrum Disorder and Visual Perception</p>
    
    
<p>Autism spectrum disorder (ASD) is increasingly prevalent, affecting 1 in every 68 children in the United States. In addition to presenting children with pervasive social and behavioral challenges, ASD is also associated with changes in visual perception. Do children with ASD actually see their worlds differently than other children? How do children with ASD perceive complex social cues, like a person’s gaze direction, and how might visual perception influence the way kids with ASD understand another person’s mental state or engage in social interactions? How do people with ASD perceive gaze on a robot’s face?</p>

  </div>
</div>

<div class="feature">
  <a class="feature-image" aria-label="Face/Emotion Perception">
    <img src="https://images.unsplash.com/photo-1423742774270-6884aac775fa?q=80&w=1471&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" loading="lazy" alt="Face/Emotion Perception" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Face/Emotion Perception</p>
    
    
<p>Faces are fascinating. They’re visually complex, they’re dynamic and they’re just about everywhere. People contort their faces to express their emotions and direct their attention. Faces also provide a means to understand what other people are thinking, feeling and seeing.
While most people have no trouble discriminating extreme facial displays, like seething rage or direct gaze, the facial cues people typically encounter are more subtle and visible for only an instant. How much about a person’s internal state can we actually access in an instant? How does the visual system determine where a person is looking? Does hearing emotional sounds change the way people see emotion?</p>

  </div>
</div>

<div class="feature" data-flip="">
  <a class="feature-image" aria-label="Perceptual Segmentation">
    <img src="https://images.unsplash.com/photo-1585507252242-11fe632c26e8?q=80&w=1470&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" loading="lazy" alt="Perceptual Segmentation" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Perceptual Segmentation</p>
    
    
<p>The world is full of redundancy. Many objects and people appear strikingly similar. Yet somehow people understand our world in terms of distinct categories: tall or flat, happy or neutral, walking toward me or to the side, familiar or unfamiliar.
This segmentation is really important when viewing many things at once, allowing people find the odd-ball, or the object of a search. What visual mechanisms allow people to parse lots of similar information at once, segmenting the world into distinct categories and directing attention toward the qualities that make each object or person unique?</p>

  </div>
</div>

<div class="feature">
  <a class="feature-image" aria-label="Perceptual Development">
    <img src="https://images.unsplash.com/photo-1495921258158-db2d5a45cb02?q=80&w=1470&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" loading="lazy" alt="Perceptual Development" onerror="this.src = '/vpec-lab.github.io/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Perceptual Development</p>
    
    
<p>What is visual experience like in childhood? Many perceptual abilities take years to develop, including distinguishing objects in time and space, filtering out distracting visual information and even remembering what has been seen. Yet, just like adults, children must navigate crowded and cluttered environments. Is the developing visual system equipped with any mechanisms for seeing many things at once? How does the ability to see the gist develop from pre-school age to adulthood? How do children perceive complex social cues like gaze and facial expression?</p>

  </div>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/vpec-lab.github.io/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="mailto:timothy.sweeny@du.edu" data-tooltip="Email" data-style="bare" aria-label="Email">
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://orcid.org/0000-0002-5602-3215" data-tooltip="ORCID" data-style="bare" aria-label="ORCID">
      <i class="icon fa-brands fa-orcid"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://scholar.google.com/citations?user=iEE5bbkAAAAJ" data-tooltip="Google Scholar" data-style="bare" aria-label="Google Scholar">
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://github.com/VPEC-Lab" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2024
    VPEC Lab
      |   University of Denver
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
